import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
import pandas as pd
import matplotlib.pyplot as plt

# Load the CSV file into a DataFrame
dataFrame = pd.read_csv(r"StressLevelDataset.csv")

# Extract features (X) and target variable (y)
X = dataFrame[['anxiety_level', 'self_esteem', 'mental_health_history', 'depression', 'headache',
               'blood_pressure', 'sleep_quality', 'breathing_problem', 'noise_level', 
               'living_conditions', 'safety', 'basic_needs', 'academic_performance', 
               'study_load', 'teacher_student_relationship', 'future_career_concerns', 
               'social_support', 'peer_pressure', 'extracurricular_activities', 'bullying']].values

y = dataFrame['stress_level'].values

# Train-validation-test split (60:20:20))
X_main, X_test, y_main, y_test = train_test_split(X, y, test_size=220, shuffle=False)
X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, test_size=220, shuffle=False)

# Map class values to stress level labels for visualization
class_labels = {0: 'Class 0', 1: 'Class 1', 2: 'Class '}

def evaluate_knn_model(k, X_train, y_train, X_val, y_val):
    knn_model = KNeighborsClassifier(n_neighbors=k)
    knn_model.fit(X_train, y_train)
    y_pred_val = knn_model.predict(X_val)
    
    accuracy_val = accuracy_score(y_val, y_pred_val)
    accuracy_train = accuracy_score(y_train, knn_model.predict(X_train))
    
    return accuracy_val, accuracy_train

def plot_confusion_matrix(ax, conf_matrix, title, k, tn, fp, fn, tp, misclassified):
    sns.heatmap(
        conf_matrix,
        annot=True,
        fmt="d",
        cmap="Greys",
        xticklabels=class_labels.values(),
        yticklabels=class_labels.values(),
        linewidths=.5,
        square=True,
        cbar=False,
        ax=ax,
        annot_kws={"color": 'white', "fontfamily": "serif", "fontsize": 12, "style": "italic", "weight": "bold", "bbox": dict(boxstyle="round", alpha=0.1, facecolor='black')}
    )
    
    ax.text(1.5, -0.2, f'Correctly Classified: {tp + tn + conf_matrix[2, 2]}', horizontalalignment='center', verticalalignment='bottom', color='green', fontweight='bold')
    ax.text(1.5, -0.3, f'Misclassified: {misclassified}', horizontalalignment='center', verticalalignment='bottom', color='red', fontweight='bold')

    ax.set_title(f'Confusion Matrix (k={k})', color='white', fontsize=14, fontweight='bold')
    ax.set_xlabel('Predicted Label', color='white', fontsize=12, fontweight='bold')
    ax.set_ylabel('Actual Label', color='white', fontsize=12, fontweight='bold')
    ax.tick_params(axis='both', colors='white')

# Create KNN models with different k values
k_values = [1, 3]
results = [evaluate_knn_model(k, X_train, y_train, X_val, y_val) for k in k_values]

# Plot confusion matrices and additional information
fig, axes = plt.subplots(nrows=1, ncols=len(k_values), figsize=(16, 6), facecolor='black')

for ax, (k, (accuracy_val, accuracy_train)) in zip(axes, zip(k_values, results)):
    knn_model = KNeighborsClassifier(n_neighbors=k)
    knn_model.fit(X_train, y_train)
    y_pred_val = knn_model.predict(X_val)
    
    # Compute the confusion matrix
    conf_matrix = confusion_matrix(y_val, y_pred_val)
    tn, fp, fn, tp = conf_matrix[0, 0], conf_matrix[0, 1], conf_matrix[1, 0], conf_matrix[1, 1]
    misclassified = fp + fn
    
    plot_confusion_matrix(ax, conf_matrix, f'Confusion Matrix (k={k})', k, tn, fp, fn, tp, misclassified)

fig.set_facecolor('black')


# Plot accuracy for different k values
k_values = np.arange(1, 20)
accuracies = []
training_errors = []
validation_errors = []

for k in k_values:
    accuracy_val, accuracy_train = evaluate_knn_model(k, X_train, y_train, X_val, y_val)
    accuracies.append(accuracy_val)
    training_errors.append(1 - accuracy_train)  # Training error is 1 - Training Accuracy
    validation_errors.append(1 - accuracy_val)  # Validation error is 1 - Validation Accuracy

# Plot Accuracy
plt.figure(figsize=(16, 6), facecolor='black')
plt.subplot(1, 3, 1)  # Add a subplot for Accuracy
plt.plot(k_values, accuracies, label='Accuracy', linestyle='-', color='blue', linewidth=2)
plt.scatter([1, 3], [accuracies[0], accuracies[2]], color='blue', marker='o', s=100)
for k, acc in zip([1, 3], [accuracies[0], accuracies[2]]):
    plt.text(k, acc, f'K={k}: {acc:.2%}', color='white', fontsize=8, ha='left', va='bottom', bbox=dict(facecolor='black', edgecolor='white', boxstyle='round', alpha=0.5))
plt.title('Accuracy for Different k Values', fontsize=14, color='white', fontweight='bold')
plt.xlabel('k value', fontsize=12, color='white')
plt.ylabel('Accuracy', fontsize=12, color='white')
plt.xticks(color='white', fontsize=10)
plt.yticks(color='white', fontsize=10)
plt.grid(True, color='white')
plt.gca().set_facecolor('black')
plt.legend()

# Add specific points for k=1 and k=3 on the Training and Validation Errors plots
specific_k_values = [1, 3]
# Create a subplot for Training Error
plt.subplot(1, 3, 2)
plt.plot(k_values, training_errors, label='Training Error', linestyle='-', color='orange', linewidth=2)
plt.scatter(specific_k_values, [training_errors[0], training_errors[2]], color='orange', marker='o', s=100)
for k, error in zip(specific_k_values, [training_errors[0], training_errors[2]]):
    plt.text(k, error, f'K={k}: {error:.2%}', color='white', fontsize=8, ha='left', va='bottom', bbox=dict(facecolor='black', edgecolor='white', boxstyle='round', alpha=0.5))
plt.title('Training Errors for Different k Values', fontsize=14, color='white', fontweight='bold')
plt.xlabel('k value', fontsize=12, color='white')
plt.ylabel('Error', fontsize=12, color='white')
plt.xticks(color='white', fontsize=10)
plt.yticks(color='white', fontsize=10)
plt.grid(True, color='white')
plt.gca().set_facecolor('black')
plt.legend()

# Create a subplot for Validation Error
plt.subplot(1, 3, 3)
plt.plot(k_values, validation_errors, label='Validation Error', linestyle='-', color='green', linewidth=2)
plt.scatter(specific_k_values, [validation_errors[0], validation_errors[2]], color='green', marker='o', s=100)
for k, error in zip(specific_k_values, [validation_errors[0], validation_errors[2]]):
    plt.text(k, error, f'K={k}: {error:.2%}', color='white', fontsize=8, ha='left', va='bottom', bbox=dict(facecolor='black', edgecolor='white', boxstyle='round', alpha=0.5))
plt.title('Validation Errors for Different k Values', fontsize=14, color='white', fontweight='bold')
plt.xlabel('k value', fontsize=12, color='white')
plt.ylabel('Error', fontsize=12, color='white')
plt.xticks(color='white', fontsize=10)
plt.yticks(color='white', fontsize=10)
plt.grid(True, color='white')
plt.gca().set_facecolor('black')
plt.legend()


plt.tight_layout()
plt.show()
